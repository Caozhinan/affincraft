{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eea46a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载PKL文件: /xcfhome/zncao02/affincraft/data/2aco-VCA/output/2aco-VCA_features_with_masif.pkl\n",
      "成功加载 1 个复合物\n",
      "数据类型: <class 'list'>\n",
      "\n",
      "================================================================================\n",
      "复合物 1: 2aco-VCA\n",
      "================================================================================\n",
      "\n",
      "=== 所有键值对和形状统计 ===\n",
      "\n",
      "--- 基本信息 ---\n",
      "  smiles: str - CCCCCC/C=C\\CCCCCCCCCC(=O)[O-]\n",
      "  rmsd: float - 0.0\n",
      "  pk: float - 6.62\n",
      "  pdbid: str - 2aco-VCA\n",
      "\n",
      "--- 图结构数据 ---\n",
      "  edge_index: ndarray shape (2, 1224)\n",
      "    数据类型: int64\n",
      "  edge_feat: ndarray shape (1224, 4)\n",
      "    数据类型: float32\n",
      "  node_feat: ndarray shape (118, 9)\n",
      "    数据类型: int64\n",
      "  coords: ndarray shape (118, 3)\n",
      "    数据类型: float64\n",
      "\n",
      "--- MaSIF特征 ---\n",
      "  masif_input_feat: ndarray shape (3444, 100, 5)\n",
      "    数据类型: float64\n",
      "  masif_rho_wrt_center: ndarray shape (3444, 100)\n",
      "    数据类型: float64\n",
      "  masif_theta_wrt_center: ndarray shape (3444, 100)\n",
      "    数据类型: float64\n",
      "  masif_mask: ndarray shape (3444, 100)\n",
      "    数据类型: float64\n",
      "  masif_desc_straight: ndarray shape (3444, 80)\n",
      "    数据类型: float32\n",
      "  masif_desc_flipped: ndarray shape (3444, 80)\n",
      "    数据类型: float32\n",
      "\n",
      "+++ masif_desc_straight 的值展示 +++\n",
      "  masif_desc_straight 前30项: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  masif_desc_straight 总形状: (3444, 80)\n",
      "\n",
      "--- 空间边数据 ---\n",
      "  lig_spatial_edge_index: ndarray shape (2, 102)\n",
      "    数据类型: int64\n",
      "  lig_spatial_edge_attr: ndarray shape (102, 4)\n",
      "    数据类型: float32\n",
      "  pro_spatial_edge_index: ndarray shape (2, 886)\n",
      "    数据类型: int64\n",
      "  pro_spatial_edge_attr: ndarray shape (886, 4)\n",
      "    数据类型: float32\n",
      "\n",
      "--- 评分特征 ---\n",
      "  gbscore: ndarray shape (400,)\n",
      "    数据类型: float64\n",
      "\n",
      "--- 其他数据 ---\n",
      "  pro_name: ndarray shape (596,)\n",
      "    数据类型: <U3\n",
      "  AA_name: ndarray shape (596,)\n",
      "    数据类型: <U3\n",
      "  num_node: ndarray shape (2,)\n",
      "    数据类型: int64\n",
      "  num_edge: ndarray shape (5,)\n",
      "    数据类型: int64\n",
      "\n",
      "--- 统计总结 ---\n",
      "  总键数: 23\n",
      "  张量/数组键数: 19\n",
      "  标量/字符串键数: 4\n",
      "\n",
      "分析完成！\n",
      "\n",
      "分析结果已保存到: analyze_result.txt\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_pkl_file_jupyter(pkl_file_path, show_all=False, output_txt='analyze_result.txt'):\n",
    "    \"\"\"分析PKL文件的内容和结构，适用于Jupyter Notebook，并将结果写入txt文件。\"\"\"\n",
    "    result_lines = []\n",
    "    def _p(s):\n",
    "        print(s)\n",
    "        result_lines.append(s)\n",
    "        \n",
    "    if not Path(pkl_file_path).exists():\n",
    "        _p(f\"错误: PKL文件不存在: {pkl_file_path}\")\n",
    "        with open(output_txt, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(result_lines))\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        _p(f\"正在加载PKL文件: {pkl_file_path}\")\n",
    "        with open(pkl_file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        _p(f\"成功加载 {len(data)} 个复合物\")\n",
    "        _p(f\"数据类型: {type(data)}\")\n",
    "\n",
    "        # 分析每个复合物\n",
    "        for idx, complex_data in enumerate(data):\n",
    "            _p('\\n' + '='*80)\n",
    "            _p(f\"复合物 {idx + 1}: {complex_data.get('pdbid', 'Unknown')}\")\n",
    "            _p('='*80)\n",
    "\n",
    "            _p(\"\\n=== 所有键值对和形状统计 ===\")\n",
    "\n",
    "            # 按类别分组显示\n",
    "            basic_info = {}\n",
    "            graph_data = {}\n",
    "            masif_features = {}\n",
    "            spatial_edges = {}\n",
    "            scores = {}\n",
    "            other_data = {}\n",
    "\n",
    "            for key, value in complex_data.items():\n",
    "                # 分类键值对\n",
    "                if key in ['pdbid', 'smiles', 'pk', 'rmsd']:\n",
    "                    basic_info[key] = value\n",
    "                elif key.startswith('masif_'):\n",
    "                    masif_features[key] = value\n",
    "                elif 'spatial' in key:\n",
    "                    spatial_edges[key] = value\n",
    "                elif key in ['node_feat', 'edge_feat', 'edge_index', 'coords']:\n",
    "                    graph_data[key] = value\n",
    "                elif key in ['rfscore', 'gbscore']:\n",
    "                    scores[key] = value\n",
    "                else:\n",
    "                    other_data[key] = value\n",
    "\n",
    "            # 打印基本信息\n",
    "            if basic_info:\n",
    "                _p(\"\\n--- 基本信息 ---\")\n",
    "                for key, value in basic_info.items():\n",
    "                    _p(f\"  {key}: {type(value).__name__} - {value}\")\n",
    "\n",
    "            # 打印图数据\n",
    "            if graph_data:\n",
    "                _p(\"\\n--- 图结构数据 ---\")\n",
    "                for key, value in graph_data.items():\n",
    "                    if isinstance(value, (np.ndarray, torch.Tensor)):\n",
    "                        _p(f\"  {key}: {type(value).__name__} shape {value.shape}\")\n",
    "                        if hasattr(value, 'dtype'):\n",
    "                            _p(f\"    数据类型: {value.dtype}\")\n",
    "                    else:\n",
    "                        _p(f\"  {key}: {type(value).__name__} - {value}\")\n",
    "\n",
    "            # 打印MaSIF特征\n",
    "            if masif_features:\n",
    "                _p(\"\\n--- MaSIF特征 ---\")\n",
    "                for key, value in masif_features.items():\n",
    "                    if isinstance(value, (np.ndarray, torch.Tensor)):\n",
    "                        _p(f\"  {key}: {type(value).__name__} shape {value.shape}\")\n",
    "                        if hasattr(value, 'dtype'):\n",
    "                            _p(f\"    数据类型: {value.dtype}\")\n",
    "                        # 检查NaN值\n",
    "                        if hasattr(value, 'isnan'):\n",
    "                            nan_count = torch.isnan(value).sum().item() if isinstance(value, torch.Tensor) else np.isnan(value).sum()\n",
    "                            _p(f\"    包含NaN值: {nan_count} 个\")\n",
    "                    else:\n",
    "                        _p(f\"  {key}: {type(value).__name__} - {value}\")\n",
    "\n",
    "                # 打印masif_desc_straight的值（如果存在，前30项）\n",
    "                if 'masif_desc_straight' in masif_features:\n",
    "                    desc = masif_features['masif_desc_straight']\n",
    "                    _p(\"\\n+++ masif_desc_straight 的值展示 +++\")\n",
    "                    if isinstance(desc, (np.ndarray, torch.Tensor)):\n",
    "                        arr = desc.cpu().numpy() if isinstance(desc, torch.Tensor) else desc\n",
    "                        _p(f\"  masif_desc_straight 前30项: {arr.flatten()[:30]}\")\n",
    "                        _p(f\"  masif_desc_straight 总形状: {arr.shape}\")\n",
    "                    else:\n",
    "                        _p(f\"  masif_desc_straight: {desc}\")\n",
    "\n",
    "            # 打印空间边数据\n",
    "            if spatial_edges:\n",
    "                _p(\"\\n--- 空间边数据 ---\")\n",
    "                for key, value in spatial_edges.items():\n",
    "                    if isinstance(value, (np.ndarray, torch.Tensor)):\n",
    "                        _p(f\"  {key}: {type(value).__name__} shape {value.shape}\")\n",
    "                        if hasattr(value, 'dtype'):\n",
    "                            _p(f\"    数据类型: {value.dtype}\")\n",
    "                    else:\n",
    "                        _p(f\"  {key}: {type(value).__name__} - {value}\")\n",
    "\n",
    "            # 打印评分数据\n",
    "            if scores:\n",
    "                _p(\"\\n--- 评分特征 ---\")\n",
    "                for key, value in scores.items():\n",
    "                    if isinstance(value, (np.ndarray, torch.Tensor)):\n",
    "                        _p(f\"  {key}: {type(value).__name__} shape {value.shape}\")\n",
    "                        if hasattr(value, 'dtype'):\n",
    "                            _p(f\"    数据类型: {value.dtype}\")\n",
    "                    else:\n",
    "                        _p(f\"  {key}: {type(value).__name__} - {value}\")\n",
    "\n",
    "            # 打印其他数据\n",
    "            if other_data:\n",
    "                _p(\"\\n--- 其他数据 ---\")\n",
    "                for key, value in other_data.items():\n",
    "                    if isinstance(value, (np.ndarray, torch.Tensor)):\n",
    "                        _p(f\"  {key}: {type(value).__name__} shape {value.shape}\")\n",
    "                        if hasattr(value, 'dtype'):\n",
    "                            _p(f\"    数据类型: {value.dtype}\")\n",
    "                    else:\n",
    "                        _p(f\"  {key}: {type(value).__name__} - {value}\")\n",
    "\n",
    "            # 统计总结\n",
    "            total_keys = len(complex_data.keys())\n",
    "            tensor_keys = sum(1 for v in complex_data.values() if isinstance(v, (np.ndarray, torch.Tensor)))\n",
    "\n",
    "            _p(f\"\\n--- 统计总结 ---\")\n",
    "            _p(f\"  总键数: {total_keys}\")\n",
    "            _p(f\"  张量/数组键数: {tensor_keys}\")\n",
    "            _p(f\"  标量/字符串键数: {total_keys - tensor_keys}\")\n",
    "\n",
    "            # 只分析第一个复合物的详细信息\n",
    "            if not show_all and idx == 0 and len(data) > 1:\n",
    "                _p(f\"\\n注意: 只显示第一个复合物的详细信息，共有 {len(data)} 个复合物\")\n",
    "                break\n",
    "\n",
    "        _p(\"\\n分析完成！\")\n",
    "\n",
    "    except Exception as e:\n",
    "        _p(f\"处理过程中出现错误: {e}\")\n",
    "        import traceback\n",
    "        tb_str = traceback.format_exc()\n",
    "        _p(tb_str)\n",
    "    \n",
    "    # 保存结果到txt文件\n",
    "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(result_lines))\n",
    "    print(f\"\\n分析结果已保存到: {output_txt}\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 只需修改下面这两行即可分析你的PKL文件\n",
    "your_pkl = '/xcfhome/zncao02/affincraft/data/2aco-VCA/output/2aco-VCA_features_with_masif.pkl'  # ← 换成你的PKL路径\n",
    "output_txt = 'analyze_result.txt'    # 输出TXT文件名\n",
    "# show_all=True显示全部复合物，False只显示第一个\n",
    "analyze_pkl_file_jupyter(your_pkl, show_all=False, output_txt=output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8c7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载PKL文件: /xcfhome/zncao02/affincraft/data/6w1i-G4P/output/6w1i-G4P_features_with_masif.pkl\n",
      "成功加载 1 个复合物\n",
      "数据类型: <class 'dict'>\n",
      "\n",
      "================================================================================\n",
      "复合物 1: 6w1i-G4P\n",
      "================================================================================\n",
      "\n",
      "=== 基本信息 ===\n",
      "PDB ID: 6w1i-G4P\n",
      "结合亲和力 (pK): 6.62\n",
      "SMILES: NC1=NC2=C(/N=C\\N2C2OC(COP(=O)([O-])OP(=O)([O-])[O-])C(OP(=O)([O-])OP(=O)([O-])[O-])C2O)C(=O)N1\n",
      "RMSD: 1.4\n",
      "\n",
      "=== 数据结构概览 ===\n",
      "  edge_index: ndarray shape (2, 2266)\n",
      "  edge_feat: ndarray shape (2266, 4)\n",
      "  node_feat: ndarray shape (170, 9)\n",
      "  coords: ndarray shape (170, 3)\n",
      "  pro_name: ndarray shape (612,)\n",
      "  AA_name: ndarray shape (612,)\n",
      "  smiles: str - NC1=NC2=C(/N=C\\N2C2OC(COP(=O)([O-])OP(=O)([O-])[O-])C(OP(=O)([O-])OP(=O)([O-])[O-])C2O)C(=O)N1\n",
      "  rmsd: float - 1.4\n",
      "  rfscore: ndarray shape (100,)\n",
      "  gbscore: ndarray shape (400,)\n",
      "  pk: float - 6.62\n",
      "  pdbid: str - 6w1i-G4P\n",
      "  num_node: ndarray shape (2,)\n",
      "  num_edge: ndarray shape (5,)\n",
      "  lig_spatial_edge_index: ndarray shape (2, 434)\n",
      "  lig_spatial_edge_attr: ndarray shape (434, 4)\n",
      "  pro_spatial_edge_index: ndarray shape (2, 1498)\n",
      "  pro_spatial_edge_attr: ndarray shape (1498, 4)\n",
      "  masif_input_feat: ndarray shape (3888, 100, 5)\n",
      "  masif_rho_wrt_center: ndarray shape (3888, 100)\n",
      "  masif_theta_wrt_center: ndarray shape (3888, 100)\n",
      "  masif_mask: ndarray shape (3888, 100)\n",
      "  masif_desc_straight: ndarray shape (3888, 80)\n",
      "  masif_desc_flipped: ndarray shape (3888, 80)\n",
      "\n",
      "=== 图结构详细信息 ===\n",
      "节点数量: 170\n",
      "边数量: 2266\n",
      "节点特征维度: 9\n",
      "边特征维度: 4\n",
      "\n",
      "=== 分子组成统计 ===\n",
      "配体节点数: 36\n",
      "蛋白质节点数: 134\n",
      "配体结构边数: 76\n",
      "蛋白质结构边数: 226\n",
      "配体-蛋白相互作用边数: 32\n",
      "配体空间边数: 434\n",
      "蛋白质空间边数: 1498\n",
      "\n",
      "=== 详细边类型分析 ===\n",
      "总边数: 2266\n",
      "\n",
      "结构边: 302 条边 (13.3%)\n",
      "  STRUCTURAL_BOND_(0, 0, 0):\n",
      "    数量: 196 条 (8.6%)\n",
      "    编码: (0, 0, 0)\n",
      "    距离范围: 1.321 - 1.616 Å\n",
      "    平均距离: 1.494 Å\n",
      "    距离标准差: 0.061 Å\n",
      "  STRUCTURAL_BOND_(0, 0, 1):\n",
      "    数量: 42 条 (1.9%)\n",
      "    编码: (0, 0, 1)\n",
      "    距离范围: 1.251 - 1.341 Å\n",
      "    平均距离: 1.323 Å\n",
      "    距离标准差: 0.022 Å\n",
      "  STRUCTURAL_BOND_(1, 0, 1):\n",
      "    数量: 36 条 (1.6%)\n",
      "    编码: (1, 0, 1)\n",
      "    距离范围: 1.226 - 1.252 Å\n",
      "    平均距离: 1.235 Å\n",
      "    距离标准差: 0.007 Å\n",
      "  STRUCTURAL_BOND_(1, 0, 0):\n",
      "    数量: 16 条 (0.7%)\n",
      "    编码: (1, 0, 0)\n",
      "    距离范围: 1.248 - 1.515 Å\n",
      "    平均距离: 1.431 Å\n",
      "    距离标准差: 0.094 Å\n",
      "  STRUCTURAL_BOND_(3, 0, 1):\n",
      "    数量: 12 条 (0.5%)\n",
      "    编码: (3, 0, 1)\n",
      "    距离范围: 1.377 - 1.391 Å\n",
      "    平均距离: 1.384 Å\n",
      "    距离标准差: 0.004 Å\n",
      "\n",
      "PLIP相互作用边: 1964 条边 (86.7%)\n",
      "  OTHERS:\n",
      "    数量: 1932 条 (85.3%)\n",
      "    编码: (5, 9, 0)\n",
      "    距离范围: 2.178 - 4.996 Å\n",
      "    平均距离: 3.712 Å\n",
      "    距离标准差: 0.856 Å\n",
      "  HYDROGEN_BOND:\n",
      "    数量: 22 条 (1.0%)\n",
      "    编码: (5, 1, 0)\n",
      "    距离范围: 2.722 - 4.078 Å\n",
      "    平均距离: 3.224 Å\n",
      "    距离标准差: 0.427 Å\n",
      "  PI_STACKING:\n",
      "    数量: 4 条 (0.2%)\n",
      "    编码: (5, 3, 0)\n",
      "    距离范围: 3.725 - 4.622 Å\n",
      "    平均距离: 4.173 Å\n",
      "    距离标准差: 0.449 Å\n",
      "  SALT_BRIDGE:\n",
      "    数量: 4 条 (0.2%)\n",
      "    编码: (5, 5, 0)\n",
      "    距离范围: 3.566 - 3.824 Å\n",
      "    平均距离: 3.695 Å\n",
      "    距离标准差: 0.129 Å\n",
      "  PI_CATION:\n",
      "    数量: 2 条 (0.1%)\n",
      "    编码: (5, 4, 0)\n",
      "    距离范围: 3.748 - 3.748 Å\n",
      "    平均距离: 3.748 Å\n",
      "    距离标准差: 0.000 Å\n",
      "\n",
      "=== 3D坐标信息 ===\n",
      "坐标形状: (170, 3)\n",
      "坐标范围:\n",
      "  X: -3.870 - 11.108\n",
      "  Y: 29.443 - 50.120\n",
      "  Z: 28.225 - 48.343\n",
      "\n",
      "=== 分子相互作用评分 ===\n",
      "RF-Score 维度: 100\n",
      "RF-Score 前10个值: [1498.0, 386.0, 402.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "GB-Score 维度: 400\n",
      "GB-Score 前10个值: [67.17842868837107, 65.08645751331349, 2.9196167123347028, 167.6287992763939, 36.804762364366724, 37.361973444604594, 2.9481496296844685, 98.34352829377566, 11.422324764320118, 15.218887090461395]\n",
      "\n",
      "分析完成！\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3  \n",
    "\"\"\"  \n",
    "PKL文件详细分析脚本 - 专门用于分析AffinCraft生成的特征文件  \n",
    "\"\"\"  \n",
    "  \n",
    "import pickle  \n",
    "import torch  \n",
    "import numpy as np  \n",
    "from pathlib import Path  \n",
    "import sys  \n",
    "  \n",
    "def analyze_edge_types_detailed(edge_attr):  \n",
    "    \"\"\"详细分析边的类型分布，包括所有PLIP相互作用类型\"\"\"  \n",
    "    edge_types = {}  \n",
    "    edge_type_stats = {}  \n",
    "      \n",
    "    # 处理numpy数组或tensor  \n",
    "    if isinstance(edge_attr, torch.Tensor):  \n",
    "        edge_attr = edge_attr.numpy()  \n",
    "      \n",
    "    for i, edge_feature in enumerate(edge_attr):  \n",
    "        if len(edge_feature) >= 3:  \n",
    "            # 前3维是边类型编码  \n",
    "            edge_type_code = tuple(edge_feature[:3].astype(int))  \n",
    "              \n",
    "            # 根据边类型映射进行分类  \n",
    "            if edge_type_code == (4, 0, 0):  \n",
    "                edge_type = \"SPATIAL_EDGE\"  \n",
    "                edge_category = \"空间边\"  \n",
    "            elif edge_type_code == (5, 1, 0):  \n",
    "                edge_type = \"HYDROGEN_BOND\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 2, 0):  \n",
    "                edge_type = \"HYDROPHOBIC_CONTACT\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 3, 0):  \n",
    "                edge_type = \"PI_STACKING\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 4, 0):  \n",
    "                edge_type = \"PI_CATION\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 5, 0):  \n",
    "                edge_type = \"SALT_BRIDGE\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 6, 0):  \n",
    "                edge_type = \"WATER_BRIDGE\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 7, 0):  \n",
    "                edge_type = \"HALOGEN_BOND\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 8, 0):  \n",
    "                edge_type = \"METAL_COMPLEX\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            elif edge_type_code == (5, 9, 0):  \n",
    "                edge_type = \"OTHERS\"  \n",
    "                edge_category = \"PLIP相互作用边\"  \n",
    "            else:  \n",
    "                # 可能是结构边（化学键）  \n",
    "                edge_type = f\"STRUCTURAL_BOND_{edge_type_code}\"  \n",
    "                edge_category = \"结构边\"  \n",
    "              \n",
    "            if edge_type not in edge_types:  \n",
    "                edge_types[edge_type] = []  \n",
    "                edge_type_stats[edge_type] = {  \n",
    "                    'category': edge_category,  \n",
    "                    'code': edge_type_code,  \n",
    "                    'count': 0,  \n",
    "                    'distances': []  \n",
    "                }  \n",
    "              \n",
    "            edge_type_stats[edge_type]['count'] += 1  \n",
    "              \n",
    "            # 如果有第4维，那是距离信息  \n",
    "            if len(edge_feature) > 3:  \n",
    "                distance = edge_feature[3]  \n",
    "                edge_types[edge_type].append(distance)  \n",
    "                edge_type_stats[edge_type]['distances'].append(distance)  \n",
    "            else:  \n",
    "                edge_types[edge_type].append(\"N/A\")  \n",
    "      \n",
    "    return edge_types, edge_type_stats  \n",
    "  \n",
    "def print_detailed_analysis(pkl_file_path):  \n",
    "    \"\"\"打印PKL文件的详细分析\"\"\"  \n",
    "      \n",
    "    # 检查文件是否存在  \n",
    "    if not Path(pkl_file_path).exists():  \n",
    "        print(f\"错误: PKL文件不存在: {pkl_file_path}\")  \n",
    "        return  \n",
    "      \n",
    "    try:  \n",
    "        # 加载pkl文件  \n",
    "        print(f\"正在加载PKL文件: {pkl_file_path}\")  \n",
    "        with open(pkl_file_path, 'rb') as f:  \n",
    "            graphs = pickle.load(f)  \n",
    "          \n",
    "        print(f\"成功加载 {len(graphs)} 个复合物\")  \n",
    "        print(f\"数据类型: {type(graphs[0])}\")  \n",
    "          \n",
    "        # 分析每个复合物  \n",
    "        for idx, graph in enumerate(graphs):  \n",
    "            print(f\"\\n{'='*80}\")  \n",
    "            print(f\"复合物 {idx + 1}: {graph.get('pdbid', 'Unknown')}\")  \n",
    "            print(f\"{'='*80}\")  \n",
    "              \n",
    "            # 基本信息  \n",
    "            print(\"\\n=== 基本信息 ===\")  \n",
    "            print(f\"PDB ID: {graph.get('pdbid', 'N/A')}\")  \n",
    "            print(f\"结合亲和力 (pK): {graph.get('pk', 'N/A')}\")  \n",
    "            print(f\"SMILES: {graph.get('smiles', 'N/A')}\")  \n",
    "            print(f\"RMSD: {graph.get('rmsd', 'N/A')}\")  \n",
    "              \n",
    "            # 数据结构概览  \n",
    "            print(\"\\n=== 数据结构概览 ===\")  \n",
    "            for key, value in graph.items():  \n",
    "                if isinstance(value, (np.ndarray, torch.Tensor)):  \n",
    "                    print(f\"  {key}: {type(value).__name__} shape {value.shape}\")  \n",
    "                else:  \n",
    "                    print(f\"  {key}: {type(value).__name__} - {value}\")  \n",
    "              \n",
    "            # 图结构详细信息  \n",
    "            print(\"\\n=== 图结构详细信息 ===\")  \n",
    "            node_feat = graph.get('node_feat', np.array([]))  \n",
    "            edge_index = graph.get('edge_index', np.array([]))  \n",
    "            edge_feat = graph.get('edge_feat', np.array([]))  \n",
    "            coords = graph.get('coords', np.array([]))  \n",
    "              \n",
    "            print(f\"节点数量: {node_feat.shape[0] if len(node_feat.shape) > 0 else 0}\")  \n",
    "            print(f\"边数量: {edge_index.shape[1] if len(edge_index.shape) > 1 else 0}\")  \n",
    "            print(f\"节点特征维度: {node_feat.shape[1] if len(node_feat.shape) > 1 else 0}\")  \n",
    "            print(f\"边特征维度: {edge_feat.shape[1] if len(edge_feat.shape) > 1 else 0}\")  \n",
    "              \n",
    "            # 分子组成统计  \n",
    "            if 'num_node' in graph and 'num_edge' in graph:  \n",
    "                print(\"\\n=== 分子组成统计 ===\")  \n",
    "                num_node = graph['num_node']  \n",
    "                num_edge = graph['num_edge']  \n",
    "                print(f\"配体节点数: {num_node[0]}\")  \n",
    "                print(f\"蛋白质节点数: {num_node[1]}\")  \n",
    "                if len(num_edge) >= 5:  \n",
    "                    print(f\"配体结构边数: {num_edge[0]}\")  \n",
    "                    print(f\"蛋白质结构边数: {num_edge[1]}\")  \n",
    "                    print(f\"配体-蛋白相互作用边数: {num_edge[2]}\")  \n",
    "                    print(f\"配体空间边数: {num_edge[3]}\")  \n",
    "                    print(f\"蛋白质空间边数: {num_edge[4]}\")  \n",
    "              \n",
    "            # 详细边类型分析  \n",
    "            if len(edge_feat.shape) > 1:  \n",
    "                print(\"\\n=== 详细边类型分析 ===\")  \n",
    "                edge_types, edge_type_stats = analyze_edge_types_detailed(edge_feat)  \n",
    "                  \n",
    "                # 总体统计  \n",
    "                total_edges = sum(stats['count'] for stats in edge_type_stats.values())  \n",
    "                print(f\"总边数: {total_edges}\")  \n",
    "                  \n",
    "                # 按类别分组显示  \n",
    "                categories = {}  \n",
    "                for edge_type, stats in edge_type_stats.items():  \n",
    "                    category = stats['category']  \n",
    "                    if category not in categories:  \n",
    "                        categories[category] = []  \n",
    "                    categories[category].append((edge_type, stats))  \n",
    "                  \n",
    "                for category, edges in categories.items():  \n",
    "                    category_total = sum(stats['count'] for _, stats in edges)  \n",
    "                    print(f\"\\n{category}: {category_total} 条边 ({category_total/total_edges*100:.1f}%)\")  \n",
    "                      \n",
    "                    for edge_type, stats in sorted(edges, key=lambda x: x[1]['count'], reverse=True):  \n",
    "                        count = stats['count']  \n",
    "                        percentage = count / total_edges * 100  \n",
    "                        print(f\"  {edge_type}:\")  \n",
    "                        print(f\"    数量: {count} 条 ({percentage:.1f}%)\")  \n",
    "                        print(f\"    编码: {stats['code']}\")  \n",
    "                          \n",
    "                        if stats['distances'] and len([d for d in stats['distances'] if d != \"N/A\"]) > 0:  \n",
    "                            distances = [d for d in stats['distances'] if d != \"N/A\"]  \n",
    "                            print(f\"    距离范围: {min(distances):.3f} - {max(distances):.3f} Å\")  \n",
    "                            print(f\"    平均距离: {np.mean(distances):.3f} Å\")  \n",
    "                            print(f\"    距离标准差: {np.std(distances):.3f} Å\")  \n",
    "              \n",
    "            # 3D坐标信息  \n",
    "            if len(coords.shape) > 1:  \n",
    "                print(\"\\n=== 3D坐标信息 ===\")  \n",
    "                print(f\"坐标形状: {coords.shape}\")  \n",
    "                print(f\"坐标范围:\")  \n",
    "                print(f\"  X: {coords[:, 0].min():.3f} - {coords[:, 0].max():.3f}\")  \n",
    "                print(f\"  Y: {coords[:, 1].min():.3f} - {coords[:, 1].max():.3f}\")  \n",
    "                print(f\"  Z: {coords[:, 2].min():.3f} - {coords[:, 2].max():.3f}\")  \n",
    "              \n",
    "            # 分子相互作用评分  \n",
    "            print(\"\\n=== 分子相互作用评分 ===\")  \n",
    "            if 'rfscore' in graph:  \n",
    "                rfscore = graph['rfscore']  \n",
    "                print(f\"RF-Score 维度: {len(rfscore)}\")  \n",
    "                print(f\"RF-Score 前10个值: {rfscore[:10].tolist()}\")  \n",
    "            if 'gbscore' in graph:  \n",
    "                gbscore = graph['gbscore']  \n",
    "                print(f\"GB-Score 维度: {len(gbscore)}\")  \n",
    "                print(f\"GB-Score 前10个值: {gbscore[:10].tolist()}\")  \n",
    "            if 'ecif' in graph:  \n",
    "                ecif = graph['ecif']  \n",
    "                print(f\"ECIF 维度: {len(ecif)}\")  \n",
    "                print(f\"ECIF 非零元素数: {np.count_nonzero(ecif)}\")  \n",
    "              \n",
    "            # MaSIF特征（如果存在）  \n",
    "            if 'masif_features' in graph:  \n",
    "                masif_features = graph['masif_features']  \n",
    "                print(f\"\\n=== MaSIF特征 ===\")  \n",
    "                print(f\"MaSIF特征形状: {masif_features.shape}\")  \n",
    "                print(f\"MaSIF特征范围: {masif_features.min():.3f} - {masif_features.max():.3f}\")  \n",
    "          \n",
    "        print(f\"\\n分析完成！\")  \n",
    "          \n",
    "    except Exception as e:  \n",
    "        print(f\"处理过程中出现错误: {e}\")  \n",
    "        import traceback  \n",
    "        traceback.print_exc()  \n",
    "  \n",
    "if __name__ == \"__main__\":  \n",
    "    # 您的PKL文件路径  \n",
    "    pkl_file_path = \"/xcfhome/zncao02/affincraft/data/6w1i-G4P/output/6w1i-G4P_features_with_masif.pkl\"  \n",
    "      \n",
    "    print_detailed_analysis(pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e8ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载PKL文件: /xcfhome/zncao02/affincraft/data/test.pkl\n",
      "成功加载 1 个复合物\n",
      "\n",
      "================================================================================\n",
      "复合物 1: 6w1i-G4P\n",
      "================================================================================\n",
      "配体原子数: 36\n",
      "蛋白质原子数: 134\n",
      "总边数: 2266\n",
      "\n",
      "=== 共价边（结构边） ===\n",
      "总边数: 290\n",
      "  PROTEIN_BOND_(0, 0, 0): 136 条 (46.9%)\n",
      "    距离范围: 1.411 - 1.543 Å\n",
      "    平均距离: 1.502 Å\n",
      "  LIGAND_BOND_(0, 0, 0): 60 条 (20.7%)\n",
      "    距离范围: 1.321 - 1.616 Å\n",
      "    平均距离: 1.477 Å\n",
      "  PROTEIN_BOND_(0, 0, 1): 42 条 (14.5%)\n",
      "    距离范围: 1.251 - 1.341 Å\n",
      "    平均距离: 1.323 Å\n",
      "  PROTEIN_BOND_(1, 0, 1): 36 条 (12.4%)\n",
      "    距离范围: 1.226 - 1.252 Å\n",
      "    平均距离: 1.235 Å\n",
      "  LIGAND_BOND_(1, 0, 0): 16 条 (5.5%)\n",
      "    距离范围: 1.248 - 1.515 Å\n",
      "    平均距离: 1.431 Å\n",
      "\n",
      "=== 内部空间边 ===\n",
      "配体内部空间边: 434 条\n",
      "  OTHERS: 434 条 (100.0%)\n",
      "    距离范围: 2.178 - 4.991 Å\n",
      "    平均距离: 3.555 Å\n",
      "\n",
      "蛋白质内部空间边: 1498 条\n",
      "  OTHERS: 1338 条 (89.3%)\n",
      "    距离范围: 2.198 - 4.996 Å\n",
      "    平均距离: 3.848 Å\n",
      "  HYDROGEN_BOND: 110 条 (7.3%)\n",
      "    距离范围: 2.205 - 3.947 Å\n",
      "    平均距离: 2.974 Å\n",
      "  HYDROPHOBIC_CONTACT: 40 条 (2.7%)\n",
      "    距离范围: 2.383 - 3.920 Å\n",
      "    平均距离: 2.745 Å\n",
      "  PI_CATION: 10 条 (0.7%)\n",
      "    距离范围: 3.395 - 4.762 Å\n",
      "    平均距离: 4.225 Å\n",
      "\n",
      "=== 蛋白-配体相互作用边 ===\n",
      "总边数: 32\n",
      "  HYDROGEN_BOND: 22 条 (68.8%)\n",
      "    距离范围: 2.722 - 4.078 Å\n",
      "    平均距离: 3.224 Å\n",
      "  PI_STACKING: 4 条 (12.5%)\n",
      "    距离范围: 3.725 - 4.622 Å\n",
      "    平均距离: 4.173 Å\n",
      "  SALT_BRIDGE: 4 条 (12.5%)\n",
      "    距离范围: 3.566 - 3.824 Å\n",
      "    平均距离: 3.695 Å\n",
      "  PI_CATION: 2 条 (6.2%)\n",
      "    距离范围: 3.748 - 3.748 Å\n",
      "    平均距离: 3.748 Å\n",
      "\n",
      "分析完成！\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  \n",
    "PKL文件边类型分离分析脚本 - 分别分析共价边、内部空间边和相互作用边  \n",
    "\"\"\"  \n",
    "  \n",
    "import pickle  \n",
    "import torch  \n",
    "import numpy as np  \n",
    "from pathlib import Path  \n",
    "  \n",
    "def analyze_edges_by_category(edge_index, edge_feat, num_ligand_atoms):  \n",
    "    \"\"\"  \n",
    "    根据边的连接模式和类型编码分离三种边类型  \n",
    "      \n",
    "    Args:  \n",
    "        edge_index: 边索引 [2, num_edges]  \n",
    "        edge_feat: 边特征 [num_edges, feat_dim]  \n",
    "        num_ligand_atoms: 配体原子数量  \n",
    "      \n",
    "    Returns:  \n",
    "        dict: 包含三种边类型的详细信息  \n",
    "    \"\"\"  \n",
    "    if isinstance(edge_feat, torch.Tensor):  \n",
    "        edge_feat = edge_feat.numpy()  \n",
    "    if isinstance(edge_index, torch.Tensor):  \n",
    "        edge_index = edge_index.numpy()  \n",
    "      \n",
    "    # 初始化三种边类型的存储  \n",
    "    structural_bonds = {'indices': [], 'features': [], 'stats': {}}  \n",
    "    internal_spatial = {'ligand': {'indices': [], 'features': [], 'stats': {}},   \n",
    "                       'protein': {'indices': [], 'features': [], 'stats': {}}}  \n",
    "    interaction_edges = {'indices': [], 'features': [], 'stats': {}}  \n",
    "      \n",
    "    for i in range(edge_index.shape[1]):  \n",
    "        src_idx, tgt_idx = edge_index[0, i], edge_index[1, i]  \n",
    "        edge_feature = edge_feat[i]  \n",
    "          \n",
    "        if len(edge_feature) >= 3:  \n",
    "            edge_type_code = tuple(edge_feature[:3].astype(int))  \n",
    "              \n",
    "            # 判断边的类型和位置  \n",
    "            src_is_ligand = src_idx < num_ligand_atoms  \n",
    "            tgt_is_ligand = tgt_idx < num_ligand_atoms  \n",
    "              \n",
    "            # 分类边类型  \n",
    "            if edge_type_code[0] in [0, 1]:  # 结构边（共价键）  \n",
    "                structural_bonds['indices'].append([src_idx, tgt_idx])  \n",
    "                structural_bonds['features'].append(edge_feature)  \n",
    "                  \n",
    "                bond_type = f\"LIGAND_BOND_{edge_type_code}\" if src_is_ligand and tgt_is_ligand else f\"PROTEIN_BOND_{edge_type_code}\"  \n",
    "                if bond_type not in structural_bonds['stats']:  \n",
    "                    structural_bonds['stats'][bond_type] = {'count': 0, 'distances': []}  \n",
    "                structural_bonds['stats'][bond_type]['count'] += 1  \n",
    "                if len(edge_feature) > 3:  \n",
    "                    structural_bonds['stats'][bond_type]['distances'].append(edge_feature[3])  \n",
    "                      \n",
    "            elif edge_type_code[0] == 4:  # 原始空间边  \n",
    "                if src_is_ligand and tgt_is_ligand:  \n",
    "                    # 配体内部空间边  \n",
    "                    internal_spatial['ligand']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['ligand']['features'].append(edge_feature)  \n",
    "                elif not src_is_ligand and not tgt_is_ligand:  \n",
    "                    # 蛋白质内部空间边  \n",
    "                    internal_spatial['protein']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['protein']['features'].append(edge_feature)  \n",
    "                else:  \n",
    "                    # 蛋白-配体相互作用边  \n",
    "                    interaction_edges['indices'].append([src_idx, tgt_idx])  \n",
    "                    interaction_edges['features'].append(edge_feature)  \n",
    "                      \n",
    "            elif edge_type_code[0] == 5:  # PLIP相互作用边  \n",
    "                # 根据原子位置判断是内部空间边还是相互作用边  \n",
    "                if src_is_ligand and tgt_is_ligand:  \n",
    "                    # 配体内部的PLIP类型空间边  \n",
    "                    internal_spatial['ligand']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['ligand']['features'].append(edge_feature)  \n",
    "                      \n",
    "                    edge_type = get_plip_edge_type_name(edge_type_code)  \n",
    "                    if edge_type not in internal_spatial['ligand']['stats']:  \n",
    "                        internal_spatial['ligand']['stats'][edge_type] = {'count': 0, 'distances': []}  \n",
    "                    internal_spatial['ligand']['stats'][edge_type]['count'] += 1  \n",
    "                    if len(edge_feature) > 3:  \n",
    "                        internal_spatial['ligand']['stats'][edge_type]['distances'].append(edge_feature[3])  \n",
    "                          \n",
    "                elif not src_is_ligand and not tgt_is_ligand:  \n",
    "                    # 蛋白质内部的PLIP类型空间边  \n",
    "                    internal_spatial['protein']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['protein']['features'].append(edge_feature)  \n",
    "                      \n",
    "                    edge_type = get_plip_edge_type_name(edge_type_code)  \n",
    "                    if edge_type not in internal_spatial['protein']['stats']:  \n",
    "                        internal_spatial['protein']['stats'][edge_type] = {'count': 0, 'distances': []}  \n",
    "                    internal_spatial['protein']['stats'][edge_type]['count'] += 1  \n",
    "                    if len(edge_feature) > 3:  \n",
    "                        internal_spatial['protein']['stats'][edge_type]['distances'].append(edge_feature[3])  \n",
    "                          \n",
    "                else:  \n",
    "                    # 蛋白-配体PLIP相互作用边  \n",
    "                    interaction_edges['indices'].append([src_idx, tgt_idx])  \n",
    "                    interaction_edges['features'].append(edge_feature)  \n",
    "                      \n",
    "                    edge_type = get_plip_edge_type_name(edge_type_code)  \n",
    "                    if edge_type not in interaction_edges['stats']:  \n",
    "                        interaction_edges['stats'][edge_type] = {'count': 0, 'distances': []}  \n",
    "                    interaction_edges['stats'][edge_type]['count'] += 1  \n",
    "                    if len(edge_feature) > 3:  \n",
    "                        interaction_edges['stats'][edge_type]['distances'].append(edge_feature[3])  \n",
    "      \n",
    "    return {  \n",
    "        'structural_bonds': structural_bonds,  \n",
    "        'internal_spatial': internal_spatial,  \n",
    "        'interaction_edges': interaction_edges  \n",
    "    }  \n",
    "  \n",
    "def get_plip_edge_type_name(edge_type_code):  \n",
    "    \"\"\"根据边类型编码返回PLIP相互作用类型名称\"\"\"  \n",
    "    plip_type_map = {  \n",
    "        (5, 1, 0): \"HYDROGEN_BOND\",  \n",
    "        (5, 2, 0): \"HYDROPHOBIC_CONTACT\",   \n",
    "        (5, 3, 0): \"PI_STACKING\",  \n",
    "        (5, 4, 0): \"PI_CATION\",  \n",
    "        (5, 5, 0): \"SALT_BRIDGE\",  \n",
    "        (5, 6, 0): \"WATER_BRIDGE\",  \n",
    "        (5, 7, 0): \"HALOGEN_BOND\",  \n",
    "        (5, 8, 0): \"METAL_COMPLEX\",  \n",
    "        (5, 9, 0): \"OTHERS\"  \n",
    "    }  \n",
    "    return plip_type_map.get(edge_type_code, f\"UNKNOWN_{edge_type_code}\")  \n",
    "  \n",
    "def print_edge_category_analysis(category_name, edge_data):  \n",
    "    \"\"\"打印特定边类别的详细分析\"\"\"  \n",
    "    print(f\"\\n=== {category_name} ===\")  \n",
    "      \n",
    "    if isinstance(edge_data, dict) and 'stats' in edge_data:  \n",
    "        # 单一类别（如结构边或相互作用边）  \n",
    "        total_edges = sum(stats['count'] for stats in edge_data['stats'].values())  \n",
    "        print(f\"总边数: {total_edges}\")  \n",
    "          \n",
    "        for edge_type, stats in sorted(edge_data['stats'].items(), key=lambda x: x[1]['count'], reverse=True):  \n",
    "            count = stats['count']  \n",
    "            percentage = count / total_edges * 100 if total_edges > 0 else 0  \n",
    "            print(f\"  {edge_type}: {count} 条 ({percentage:.1f}%)\")  \n",
    "              \n",
    "            if stats['distances']:  \n",
    "                distances = stats['distances']  \n",
    "                print(f\"    距离范围: {min(distances):.3f} - {max(distances):.3f} Å\")  \n",
    "                print(f\"    平均距离: {np.mean(distances):.3f} Å\")  \n",
    "                  \n",
    "    elif isinstance(edge_data, dict) and 'ligand' in edge_data:  \n",
    "        # 内部空间边（包含配体和蛋白质）  \n",
    "        ligand_total = sum(stats['count'] for stats in edge_data['ligand']['stats'].values())  \n",
    "        protein_total = sum(stats['count'] for stats in edge_data['protein']['stats'].values())  \n",
    "          \n",
    "        print(f\"配体内部空间边: {ligand_total} 条\")  \n",
    "        for edge_type, stats in sorted(edge_data['ligand']['stats'].items(), key=lambda x: x[1]['count'], reverse=True):  \n",
    "            count = stats['count']  \n",
    "            percentage = count / ligand_total * 100 if ligand_total > 0 else 0  \n",
    "            print(f\"  {edge_type}: {count} 条 ({percentage:.1f}%)\")  \n",
    "            if stats['distances']:  \n",
    "                distances = stats['distances']  \n",
    "                print(f\"    距离范围: {min(distances):.3f} - {max(distances):.3f} Å\")  \n",
    "                print(f\"    平均距离: {np.mean(distances):.3f} Å\")  \n",
    "          \n",
    "        print(f\"\\n蛋白质内部空间边: {protein_total} 条\")  \n",
    "        for edge_type, stats in sorted(edge_data['protein']['stats'].items(), key=lambda x: x[1]['count'], reverse=True):  \n",
    "            count = stats['count']  \n",
    "            percentage = count / protein_total * 100 if protein_total > 0 else 0  \n",
    "            print(f\"  {edge_type}: {count} 条 ({percentage:.1f}%)\")  \n",
    "            if stats['distances']:  \n",
    "                distances = stats['distances']  \n",
    "                print(f\"    距离范围: {min(distances):.3f} - {max(distances):.3f} Å\")  \n",
    "                print(f\"    平均距离: {np.mean(distances):.3f} Å\")  \n",
    "  \n",
    "def analyze_pkl_by_edge_types(pkl_file_path):  \n",
    "    \"\"\"按边类型分析PKL文件\"\"\"  \n",
    "      \n",
    "    if not Path(pkl_file_path).exists():  \n",
    "        print(f\"错误: PKL文件不存在: {pkl_file_path}\")  \n",
    "        return  \n",
    "      \n",
    "    try:  \n",
    "        print(f\"正在加载PKL文件: {pkl_file_path}\")  \n",
    "        with open(pkl_file_path, 'rb') as f:  \n",
    "            graphs = pickle.load(f)  \n",
    "          \n",
    "        print(f\"成功加载 {len(graphs)} 个复合物\")  \n",
    "          \n",
    "        for idx, graph in enumerate(graphs):  \n",
    "            print(f\"\\n{'='*80}\")  \n",
    "            print(f\"复合物 {idx + 1}: {graph.get('pdbid', 'Unknown')}\")  \n",
    "            print(f\"{'='*80}\")  \n",
    "              \n",
    "            # 获取基本信息  \n",
    "            edge_index = graph.get('edge_index', np.array([]))  \n",
    "            edge_feat = graph.get('edge_feat', np.array([]))  \n",
    "            num_node = graph.get('num_node', [0, 0])  \n",
    "            num_ligand_atoms = num_node[0] if len(num_node) > 0 else 0  \n",
    "              \n",
    "            print(f\"配体原子数: {num_ligand_atoms}\")  \n",
    "            print(f\"蛋白质原子数: {num_node[1] if len(num_node) > 1 else 0}\")  \n",
    "            print(f\"总边数: {edge_index.shape[1] if len(edge_index.shape) > 1 else 0}\")  \n",
    "              \n",
    "            if len(edge_index.shape) > 1 and len(edge_feat.shape) > 1:  \n",
    "                # 分析边类型  \n",
    "                edge_analysis = analyze_edges_by_category(edge_index, edge_feat, num_ligand_atoms)  \n",
    "                  \n",
    "                # 打印三种边类型的详细分析  \n",
    "                print_edge_category_analysis(\"共价边（结构边）\", edge_analysis['structural_bonds'])  \n",
    "                print_edge_category_analysis(\"内部空间边\", edge_analysis['internal_spatial'])  \n",
    "                print_edge_category_analysis(\"蛋白-配体相互作用边\", edge_analysis['interaction_edges'])  \n",
    "          \n",
    "        print(f\"\\n分析完成！\")  \n",
    "          \n",
    "    except Exception as e:  \n",
    "        print(f\"处理过程中出现错误: {e}\")  \n",
    "        import traceback  \n",
    "        traceback.print_exc()  \n",
    "  \n",
    "if __name__ == \"__main__\":  \n",
    "    # 您的PKL文件路径  \n",
    "    pkl_file_path = \"/xcfhome/zncao02/affincraft/data/test.pkl\"  \n",
    "      \n",
    "    analyze_pkl_by_edge_types(pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44556479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc20d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载PKL文件: /xcfhome/zncao02/affincraft/data/2aco.pkl\n",
      "成功加载 1 个复合物\n",
      "\n",
      "================================================================================\n",
      "复合物 1: 2aco-VCA\n",
      "================================================================================\n",
      "配体原子数: 20\n",
      "蛋白质原子数: 98\n",
      "总边数: 1224\n",
      "\n",
      "=== 共价边（结构边） ===\n",
      "总边数: 146\n",
      "  PROTEIN_BOND_(0, 0, 0): 72 条 (49.3%)\n",
      "    距离范围: 1.423 - 1.602 Å\n",
      "    平均距离: 1.503 Å\n",
      "  LIGAND_BOND_(0, 0, 0): 34 条 (23.3%)\n",
      "    距离范围: 1.251 - 1.536 Å\n",
      "    平均距离: 1.497 Å\n",
      "  PROTEIN_BOND_(1, 0, 1): 20 条 (13.7%)\n",
      "    距离范围: 1.219 - 1.334 Å\n",
      "    平均距离: 1.243 Å\n",
      "  PROTEIN_BOND_(0, 0, 1): 16 条 (11.0%)\n",
      "    距离范围: 1.249 - 1.396 Å\n",
      "    平均距离: 1.329 Å\n",
      "  LIGAND_BOND_(1, 0, 0): 4 条 (2.7%)\n",
      "    距离范围: 1.250 - 1.527 Å\n",
      "    平均距离: 1.389 Å\n",
      "\n",
      "=== 内部空间边 ===\n",
      "配体内部空间边: 102 条\n",
      "  OTHERS: 102 条 (100.0%)\n",
      "    距离范围: 2.200 - 4.978 Å\n",
      "    平均距离: 3.434 Å\n",
      "\n",
      "蛋白质内部空间边: 886 条\n",
      "  OTHERS: 624 条 (70.4%)\n",
      "    距离范围: 2.192 - 4.983 Å\n",
      "    平均距离: 3.868 Å\n",
      "  HYDROPHOBIC_CONTACT: 118 条 (13.3%)\n",
      "    距离范围: 2.373 - 3.991 Å\n",
      "    平均距离: 2.851 Å\n",
      "  PI_STACKING: 72 条 (8.1%)\n",
      "    距离范围: 2.136 - 4.924 Å\n",
      "    平均距离: 3.648 Å\n",
      "  HYDROGEN_BOND: 42 条 (4.7%)\n",
      "    距离范围: 2.233 - 3.703 Å\n",
      "    平均距离: 2.829 Å\n",
      "  PI_CATION: 26 条 (2.9%)\n",
      "    距离范围: 3.164 - 4.858 Å\n",
      "    平均距离: 4.088 Å\n",
      "  SALT_BRIDGE: 4 条 (0.5%)\n",
      "    距离范围: 4.321 - 4.864 Å\n",
      "    平均距离: 4.592 Å\n",
      "\n",
      "=== 蛋白-配体相互作用边 ===\n",
      "总边数: 22\n",
      "  HYDROPHOBIC_CONTACT: 22 条 (100.0%)\n",
      "    距离范围: 3.429 - 3.973 Å\n",
      "    平均距离: 3.747 Å\n",
      "\n",
      "分析完成！\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  \n",
    "PKL文件边类型分离分析脚本 - 分别分析共价边、内部空间边和相互作用边  \n",
    "\"\"\"  \n",
    "  \n",
    "import pickle  \n",
    "import torch  \n",
    "import numpy as np  \n",
    "from pathlib import Path  \n",
    "  \n",
    "def analyze_edges_by_category(edge_index, edge_feat, num_ligand_atoms):  \n",
    "    \"\"\"  \n",
    "    根据边的连接模式和类型编码分离三种边类型  \n",
    "      \n",
    "    Args:  \n",
    "        edge_index: 边索引 [2, num_edges]  \n",
    "        edge_feat: 边特征 [num_edges, feat_dim]  \n",
    "        num_ligand_atoms: 配体原子数量  \n",
    "      \n",
    "    Returns:  \n",
    "        dict: 包含三种边类型的详细信息  \n",
    "    \"\"\"  \n",
    "    if isinstance(edge_feat, torch.Tensor):  \n",
    "        edge_feat = edge_feat.numpy()  \n",
    "    if isinstance(edge_index, torch.Tensor):  \n",
    "        edge_index = edge_index.numpy()  \n",
    "      \n",
    "    # 初始化三种边类型的存储  \n",
    "    structural_bonds = {'indices': [], 'features': [], 'stats': {}}  \n",
    "    internal_spatial = {'ligand': {'indices': [], 'features': [], 'stats': {}},   \n",
    "                       'protein': {'indices': [], 'features': [], 'stats': {}}}  \n",
    "    interaction_edges = {'indices': [], 'features': [], 'stats': {}}  \n",
    "      \n",
    "    for i in range(edge_index.shape[1]):  \n",
    "        src_idx, tgt_idx = edge_index[0, i], edge_index[1, i]  \n",
    "        edge_feature = edge_feat[i]  \n",
    "          \n",
    "        if len(edge_feature) >= 3:  \n",
    "            edge_type_code = tuple(edge_feature[:3].astype(int))  \n",
    "              \n",
    "            # 判断边的类型和位置  \n",
    "            src_is_ligand = src_idx < num_ligand_atoms  \n",
    "            tgt_is_ligand = tgt_idx < num_ligand_atoms  \n",
    "              \n",
    "            # 分类边类型  \n",
    "            if edge_type_code[0] in [0, 1]:  # 结构边（共价键）  \n",
    "                structural_bonds['indices'].append([src_idx, tgt_idx])  \n",
    "                structural_bonds['features'].append(edge_feature)  \n",
    "                  \n",
    "                bond_type = f\"LIGAND_BOND_{edge_type_code}\" if src_is_ligand and tgt_is_ligand else f\"PROTEIN_BOND_{edge_type_code}\"  \n",
    "                if bond_type not in structural_bonds['stats']:  \n",
    "                    structural_bonds['stats'][bond_type] = {'count': 0, 'distances': []}  \n",
    "                structural_bonds['stats'][bond_type]['count'] += 1  \n",
    "                if len(edge_feature) > 3:  \n",
    "                    structural_bonds['stats'][bond_type]['distances'].append(edge_feature[3])  \n",
    "                      \n",
    "            elif edge_type_code[0] == 4:  # 原始空间边  \n",
    "                if src_is_ligand and tgt_is_ligand:  \n",
    "                    # 配体内部空间边  \n",
    "                    internal_spatial['ligand']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['ligand']['features'].append(edge_feature)  \n",
    "                elif not src_is_ligand and not tgt_is_ligand:  \n",
    "                    # 蛋白质内部空间边  \n",
    "                    internal_spatial['protein']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['protein']['features'].append(edge_feature)  \n",
    "                else:  \n",
    "                    # 蛋白-配体相互作用边  \n",
    "                    interaction_edges['indices'].append([src_idx, tgt_idx])  \n",
    "                    interaction_edges['features'].append(edge_feature)  \n",
    "                      \n",
    "            elif edge_type_code[0] == 5:  # PLIP相互作用边  \n",
    "                # 根据原子位置判断是内部空间边还是相互作用边  \n",
    "                if src_is_ligand and tgt_is_ligand:  \n",
    "                    # 配体内部的PLIP类型空间边  \n",
    "                    internal_spatial['ligand']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['ligand']['features'].append(edge_feature)  \n",
    "                      \n",
    "                    edge_type = get_plip_edge_type_name(edge_type_code)  \n",
    "                    if edge_type not in internal_spatial['ligand']['stats']:  \n",
    "                        internal_spatial['ligand']['stats'][edge_type] = {'count': 0, 'distances': []}  \n",
    "                    internal_spatial['ligand']['stats'][edge_type]['count'] += 1  \n",
    "                    if len(edge_feature) > 3:  \n",
    "                        internal_spatial['ligand']['stats'][edge_type]['distances'].append(edge_feature[3])  \n",
    "                          \n",
    "                elif not src_is_ligand and not tgt_is_ligand:  \n",
    "                    # 蛋白质内部的PLIP类型空间边  \n",
    "                    internal_spatial['protein']['indices'].append([src_idx, tgt_idx])  \n",
    "                    internal_spatial['protein']['features'].append(edge_feature)  \n",
    "                      \n",
    "                    edge_type = get_plip_edge_type_name(edge_type_code)  \n",
    "                    if edge_type not in internal_spatial['protein']['stats']:  \n",
    "                        internal_spatial['protein']['stats'][edge_type] = {'count': 0, 'distances': []}  \n",
    "                    internal_spatial['protein']['stats'][edge_type]['count'] += 1  \n",
    "                    if len(edge_feature) > 3:  \n",
    "                        internal_spatial['protein']['stats'][edge_type]['distances'].append(edge_feature[3])  \n",
    "                          \n",
    "                else:  \n",
    "                    # 蛋白-配体PLIP相互作用边  \n",
    "                    interaction_edges['indices'].append([src_idx, tgt_idx])  \n",
    "                    interaction_edges['features'].append(edge_feature)  \n",
    "                      \n",
    "                    edge_type = get_plip_edge_type_name(edge_type_code)  \n",
    "                    if edge_type not in interaction_edges['stats']:  \n",
    "                        interaction_edges['stats'][edge_type] = {'count': 0, 'distances': []}  \n",
    "                    interaction_edges['stats'][edge_type]['count'] += 1  \n",
    "                    if len(edge_feature) > 3:  \n",
    "                        interaction_edges['stats'][edge_type]['distances'].append(edge_feature[3])  \n",
    "      \n",
    "    return {  \n",
    "        'structural_bonds': structural_bonds,  \n",
    "        'internal_spatial': internal_spatial,  \n",
    "        'interaction_edges': interaction_edges  \n",
    "    }  \n",
    "  \n",
    "def get_plip_edge_type_name(edge_type_code):  \n",
    "    \"\"\"根据边类型编码返回PLIP相互作用类型名称\"\"\"  \n",
    "    plip_type_map = {  \n",
    "        (5, 1, 0): \"HYDROGEN_BOND\",  \n",
    "        (5, 2, 0): \"HYDROPHOBIC_CONTACT\",   \n",
    "        (5, 3, 0): \"PI_STACKING\",  \n",
    "        (5, 4, 0): \"PI_CATION\",  \n",
    "        (5, 5, 0): \"SALT_BRIDGE\",  \n",
    "        (5, 6, 0): \"WATER_BRIDGE\",  \n",
    "        (5, 7, 0): \"HALOGEN_BOND\",  \n",
    "        (5, 8, 0): \"METAL_COMPLEX\",  \n",
    "        (5, 9, 0): \"OTHERS\"  \n",
    "    }  \n",
    "    return plip_type_map.get(edge_type_code, f\"UNKNOWN_{edge_type_code}\")  \n",
    "  \n",
    "def print_edge_category_analysis(category_name, edge_data):  \n",
    "    \"\"\"打印特定边类别的详细分析\"\"\"  \n",
    "    print(f\"\\n=== {category_name} ===\")  \n",
    "      \n",
    "    if isinstance(edge_data, dict) and 'stats' in edge_data:  \n",
    "        # 单一类别（如结构边或相互作用边）  \n",
    "        total_edges = sum(stats['count'] for stats in edge_data['stats'].values())  \n",
    "        print(f\"总边数: {total_edges}\")  \n",
    "          \n",
    "        for edge_type, stats in sorted(edge_data['stats'].items(), key=lambda x: x[1]['count'], reverse=True):  \n",
    "            count = stats['count']  \n",
    "            percentage = count / total_edges * 100 if total_edges > 0 else 0  \n",
    "            print(f\"  {edge_type}: {count} 条 ({percentage:.1f}%)\")  \n",
    "              \n",
    "            if stats['distances']:  \n",
    "                distances = stats['distances']  \n",
    "                print(f\"    距离范围: {min(distances):.3f} - {max(distances):.3f} Å\")  \n",
    "                print(f\"    平均距离: {np.mean(distances):.3f} Å\")  \n",
    "                  \n",
    "    elif isinstance(edge_data, dict) and 'ligand' in edge_data:  \n",
    "        # 内部空间边（包含配体和蛋白质）  \n",
    "        ligand_total = sum(stats['count'] for stats in edge_data['ligand']['stats'].values())  \n",
    "        protein_total = sum(stats['count'] for stats in edge_data['protein']['stats'].values())  \n",
    "          \n",
    "        print(f\"配体内部空间边: {ligand_total} 条\")  \n",
    "        for edge_type, stats in sorted(edge_data['ligand']['stats'].items(), key=lambda x: x[1]['count'], reverse=True):  \n",
    "            count = stats['count']  \n",
    "            percentage = count / ligand_total * 100 if ligand_total > 0 else 0  \n",
    "            print(f\"  {edge_type}: {count} 条 ({percentage:.1f}%)\")  \n",
    "            if stats['distances']:  \n",
    "                distances = stats['distances']  \n",
    "                print(f\"    距离范围: {min(distances):.3f} - {max(distances):.3f} Å\")  \n",
    "                print(f\"    平均距离: {np.mean(distances):.3f} Å\")  \n",
    "          \n",
    "        print(f\"\\n蛋白质内部空间边: {protein_total} 条\")  \n",
    "        for edge_type, stats in sorted(edge_data['protein']['stats'].items(), key=lambda x: x[1]['count'], reverse=True):  \n",
    "            count = stats['count']  \n",
    "            percentage = count / protein_total * 100 if protein_total > 0 else 0  \n",
    "            print(f\"  {edge_type}: {count} 条 ({percentage:.1f}%)\")  \n",
    "            if stats['distances']:  \n",
    "                distances = stats['distances']  \n",
    "                print(f\"    距离范围: {min(distances):.3f} - {max(distances):.3f} Å\")  \n",
    "                print(f\"    平均距离: {np.mean(distances):.3f} Å\")  \n",
    "  \n",
    "def analyze_pkl_by_edge_types(pkl_file_path):  \n",
    "    \"\"\"按边类型分析PKL文件\"\"\"  \n",
    "      \n",
    "    if not Path(pkl_file_path).exists():  \n",
    "        print(f\"错误: PKL文件不存在: {pkl_file_path}\")  \n",
    "        return  \n",
    "      \n",
    "    try:  \n",
    "        print(f\"正在加载PKL文件: {pkl_file_path}\")  \n",
    "        with open(pkl_file_path, 'rb') as f:  \n",
    "            graphs = pickle.load(f)  \n",
    "          \n",
    "        print(f\"成功加载 {len(graphs)} 个复合物\")  \n",
    "          \n",
    "        for idx, graph in enumerate(graphs):  \n",
    "            print(f\"\\n{'='*80}\")  \n",
    "            print(f\"复合物 {idx + 1}: {graph.get('pdbid', 'Unknown')}\")  \n",
    "            print(f\"{'='*80}\")  \n",
    "              \n",
    "            # 获取基本信息  \n",
    "            edge_index = graph.get('edge_index', np.array([]))  \n",
    "            edge_feat = graph.get('edge_feat', np.array([]))  \n",
    "            num_node = graph.get('num_node', [0, 0])  \n",
    "            num_ligand_atoms = num_node[0] if len(num_node) > 0 else 0  \n",
    "              \n",
    "            print(f\"配体原子数: {num_ligand_atoms}\")  \n",
    "            print(f\"蛋白质原子数: {num_node[1] if len(num_node) > 1 else 0}\")  \n",
    "            print(f\"总边数: {edge_index.shape[1] if len(edge_index.shape) > 1 else 0}\")  \n",
    "              \n",
    "            if len(edge_index.shape) > 1 and len(edge_feat.shape) > 1:  \n",
    "                # 分析边类型  \n",
    "                edge_analysis = analyze_edges_by_category(edge_index, edge_feat, num_ligand_atoms)  \n",
    "                  \n",
    "                # 打印三种边类型的详细分析  \n",
    "                print_edge_category_analysis(\"共价边（结构边）\", edge_analysis['structural_bonds'])  \n",
    "                print_edge_category_analysis(\"内部空间边\", edge_analysis['internal_spatial'])  \n",
    "                print_edge_category_analysis(\"蛋白-配体相互作用边\", edge_analysis['interaction_edges'])  \n",
    "          \n",
    "        print(f\"\\n分析完成！\")  \n",
    "          \n",
    "    except Exception as e:  \n",
    "        print(f\"处理过程中出现错误: {e}\")  \n",
    "        import traceback  \n",
    "        traceback.print_exc()  \n",
    "  \n",
    "if __name__ == \"__main__\":  \n",
    "    # 您的PKL文件路径  \n",
    "    pkl_file_path = \"/xcfhome/zncao02/affincraft/data/2aco.pkl\"  \n",
    "      \n",
    "    analyze_pkl_by_edge_types(pkl_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynaformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
